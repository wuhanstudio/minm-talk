<!doctype html>
<html lang="en">

    <head>
        <meta charset="utf-8">

        <title>MinM Attack</title>

        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

        <link rel="stylesheet" href="dist/reveal.css">
        <link rel="stylesheet" href="dist/theme/white.css" id="theme">
        <link rel="stylesheet" href="plugin/highlight/monokai.css">
        
        <link rel="stylesheet" href="style.css">

        <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
        <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>

        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">

        <link rel="stylesheet" href="plugin/chalkboard/style.css">
        <link rel="stylesheet" href="plugin/customcontrols/style.css">

    </head>

    <body>

        <div class="reveal" >

            <div class="slides">

                <section data-auto-animate>
                    <span class="menu-title" style="display: none">Overview</span>
                    <h3 class="r-fit-text">Man-in-the-Middle Attack against Object Detection</h3>
                    <p class="name">Han Wu, Sareh Rowlands, and Johan Wahlstrom</p>
                    <div class="r-vstack">
                        <img class="" src="images/overview.png">
                    </div>
                    <div>
                        <!-- <img src="images/wuhanstudio.jpg" class="wuhanstudio"> -->
                        <!-- <p class="name">Han Wu,  &nbsp;<i class="fab fa-github"></i>&nbsp; <a href="https://github.com/wuhanstudio/">@wuhanstudio</a></p> -->
                        <p class="name" data-fragment-index="1" style="color: blue;font-size: 28px;"> Is Deep Learning secure for Robots?</p>
                    </div>

                    <p style="font-size: 22px;"><i class="fab fa-github"></i> &nbsp; <a href="https://github.com/wuhanstudio/adversarial-camera">Source Code</a></p>

                    <aside class="notes">
                        Hi, I'm a 2nd-year Ph.D. Student. I would like to introduce man-in-the-middle attack against object detection system. Well, is it possible to attack an object detection system? Say for example, here' we have .... But why do I do this?
                    </aside>
                </section>

                <!-- <section>
                    <h2>Background</h2>
                    <p class="" data-fragment-index="1" style="color: blue; font-size: 30px;"> Why do we attack the object detection system?</p>
                     <aside class="notes">
                        Why do we attack the object detection system?
                    </aside>
                </section> -->

                <section data-background-video="images/demo.mp4" data-background-video data-background-video-muted data-menu-title="Demo Video">
                    <aside class="notes">
                    </aside>
                </section>

                <section data-background-video="images/attack.mp4" data-background-video data-background-video-muted>
                    <aside class="notes">
                    </aside>
                </section>

                <section data-menu-title="Real-time Adversarial Attacks">
                    <!-- <p class="" style="font-size: 35px;">Deep Learning: From Data Center to Edge Devices</p> -->
                    <!-- <img src="images/data_center_edger.png" style="width: 65%; margin-bottom: 0;" alt=""> -->
                    <!-- <span class="fragment r-fit-text">Intelligent robots possess a more comprehensive perception of environments.</span> -->
                    <div class="r-vstack">
                        <p style="font-size:0.8em">Deep learning models are vulnerable to adversarial attacks.</p>
                        <img src="images/daedalus.png" style="width: 80%;" alt="">
                    </div>
                    <p style="font-size:0.6em" class="fragment" data-fragment-index="1">To achieve <strong>real-time</strong> adversarial attacks, we need to solve two problems:</p>
                    <ul>
                        <li class="fragment" data-fragment-index="2">
                            <span style="font-size:0.6em">How to generate the perturbation?</span><span class="fragment" data-fragment-index="4"  style="color:blue; font-size:0.6em"> (The PCB Attack)</span>
                        </li>
                        <li class="fragment" data-fragment-index="3">
                            <span style="font-size:0.6em">How to apply the perturbation?</span><span class="fragment" data-fragment-index="5"  style="color:blue; font-size:0.6em"> (The Man-in-the-Middle Attack)</span>
                        </li>
                    </ul>
                    <aside class="notes">
                        Because Deep learning models are moving from data centres to edge devices.We have more and more deep learning models deployed on edge devices, such as automous driving car. We know that deep learning models require large amounts of computational resources and energy. Twenty years ago, they are only available in data centres. Data cenres are usually highly secure in a dedicated space within a building, but edge devices are not, they are exposed to the outside world directly. Now, we have more computational resources on edge devices. Is it secure to deploy deep learning models on edge devices? Unfortunately, it is not. Deep learning models are vulnerable to adversarial attacks. This is not a secret. It has been over 8 years since the first adversarial attack against deep learning models.
                    </aside>
                </section>

                <section data-menu-title="Step 1: Generating the Perturbation">
                    <h6 style="margin-top: 30px; margin-bottom: 10px;">Step 1: Generating the perturbation (The PCB Attack)</h6>
                    <div class="r-hstack">
                        <p style="font-size: 25px;">Prior Research 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            Our Method</p>
                    </div>
                    <div class="r-hstack">
                        <video  autoplay muted width="35%">
                            <source src="images/no_decay.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video>
                          &nbsp;&nbsp;&nbsp;&nbsp;
                          <video  autoplay muted width="35%">
                            <source src="images/with_decay.mp4" type="video/mp4">
                            Your browser does not support the video tag.
                          </video>
                    </div>
                    <div class="r-hstack">
                        <p style="font-size: 20px;">No learning rate decay 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 
                            With learning rate decay</p>
                    </div>
                    <p style="font-size: 25px; margin-top: 0; margin-bottom: 0;" class="fragment"> Our method generates more bounding boxes, and have less variation.</p>
                    <img src="images/results.png" class="fragment" width="80%">
                </section>

                <section data-menu-title="Step 2: Applying the Perturbation">
                    <!-- <p class="" style="font-size: 35px;">Deep Learning: From Data Center to Edge Devices</p> -->
                    <!-- <img src="images/data_center_edger.png" style="width: 65%; margin-bottom: 0;" alt=""> -->
                    <!-- <span class="fragment r-fit-text">Intelligent robots possess a more comprehensive perception of environments.</span> -->
                    <div class="r-vstack">
                        <h6>Step 2: Applying the perturbation (The Man-in-the-Middle Attack)</h6>
                    </div>
                    <br />
                    <img src="images/attacks.jpg" width="100%">

                    <aside class="notes">
                        Because Deep learning models are moving from data centres to edge devices.We have more and more deep learning models deployed on edge devices, such as automous driving car. We know that deep learning models require large amounts of computational resources and energy. Twenty years ago, they are only available in data centres. Data cenres are usually highly secure in a dedicated space within a building, but edge devices are not, they are exposed to the outside world directly. Now, we have more computational resources on edge devices. Is it secure to deploy deep learning models on edge devices? Unfortunately, it is not. Deep learning models are vulnerable to adversarial attacks. This is not a secret. It has been over 8 years since the first adversarial attack against deep learning models.
                    </aside>
                </section>

                <!-- <section>
                    <p class="" style="font-size: 35px;">Is the attack possible in practice?</p>
                    <div class="r-stack">
                        <img class="fragment fade-in-then-out" data-fragment-index="1" src="images/detection.png" >
                        <img class="fragment fade-in-then-out" data-fragment-index="2" src="images/digital.png" >
                        <img class="fragment" data-fragment-index="3" src="images/physical.png" >
                      </div>
                    <p class="r-fit-text">Deep neural networks are vulnerable to adversarial attacks in various tasks.</p>
                    <p class="" style="font-size: 28px;">Adversarial attacks against image classification</p>
                    <p class="fragment r-fit-text">Instead of minimizing the loss function, the adversarial attack maximizes it.</p>
                    <div class="fragment r-vstack" data-fragment-index="4">
                        <img src="images/prior.png" alt="">
                    </div>
                    <p class="fragment" data-fragment-index="6" style="font-size: 22px;">Research interests are shifting from digital attacks to physical attacks.</p>
                    <span class="fragment" data-fragment-index="7" style="font-size: 22px; color:blue">Can we make digital perturbations feasible?</span>
                    <aside class="notes">
                    </aside>
                </section> -->
        
                <!-- <section>
                    <img src="images/prior.png" alt="" />
                    <div class="fragment r-vstack">
                        <img src="images/after.png" alt="">
                    </div>
                    <span class="" style="font-size: 28px;">Man-in-the-Middle Attack against Object Detection</span>
                    <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section>
                    <h2>Short Demo</h2>
                    <p class="" data-fragment-index="1" style="color: blue; font-size: 30px;"> Man-in-the-middle Attack</p>
                     <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section data-background-video="images/step1_1.mp4" 
                data-background-video data-background-video-muted>
                    <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section data-background-video="images/step2.mp4" 
                data-background-video data-background-video-muted>
                    <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section>
                    <h2 style="font-size: 35px;">Step 1: Deploy the hardware</h2>
                    <div class="fragment r-vstack">
                        <img src="images/apollo.png" width="55%" alt="">
                        <img src="images/hardware.png" width="55%" alt="">
                    </div>
                    <p class="name">Baidu Apollo: &nbsp;<i class="fab fa-github"></i>&nbsp; <a href="https://github.com/ApolloAuto/apollo">An open autonomous driving platform.</a></p>
                    <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section>
                    <h2 style="font-size: 35px;">Step 1: Deploy the hardware</h2>
                    <img src="images/step1s.png" class="" />
                    <img src="images/invertible.png" class="fragment fade-in" />
                    <p class="name">Open Source: &nbsp;<i class="fab fa-github"></i>&nbsp; <a href="https://github.com/wuhanstudio/adversarial-camera">Adversarial Camera</a></p>
                    <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section>
                    <h2 class="r-fit-text">Step 2: The WHite-box Adversarial Toolbox (WHAT)</h2>
                    <p style="font-size: 22px; text-align: left;" class="fragment">For each input image $x$, the detection model outputs $S$ bounding boxes $\{\hat{o}_1, \hat{o}_2, ..., \hat{o}_S\}$.</p>
                    <div class="fragment">
                        <p style="font-size: 22px; text-align: left;">Each output $\hat{o}_i=(\hat{b}_i, \hat{c}_i, \hat{p}_i)$ contains a bounding box $\hat{b}_i=(\hat{b}_i^x, \hat{b}_i^y, \hat{b}_i^w, \hat{b}_i^h)$.</p>
                        <img src="images/y.jpg" style="margin-top: 0; margin-bottom: 0;">
                    </div>
                    <p style="font-size: 22px; margin-top: 0; text-align: left;" class="fragment">A confidence value $\hat{c}_i \in [0, 1]$, and a probability vevtor $\hat{p}_i=(\hat{p}_i^1, \hat{p}_i^2, ..., \hat{p}_i^K)$ for $K$ classes.</p>
                    <p style="font-size: 22px; text-align: left; margin-bottom: 0;" class="fragment">
                        We would like to generate an adversarial example $x'$: $$min||x'-x||_p \quad s.t. \hat{O}(x') \neq \hat{O}(x)$$
                    </p>
                    <div class="r-hstack">
                        <div class="r-vstack">
                            <img src="images/no_attack.gif">
                            <p class="" style="margin-top: 0; font-size: 20px;">No attack</p>
                        </div>
                        <div class="r-vstack">&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        <div class="r-vstack">
                            <img src="images/attack.gif">
                            <p class="" style="margin-top: 0; font-size: 20px;">Under attack</p>
                        </div>
                    </div>
                    <aside class="notes">
                    </aside>
                </section> -->

                <!-- <section>
                    <h2 class="r-fit-text">Step 2: The WHite-box Adversarial Toolbox (WHAT)</h2>
                    <p style="font-size: 24px; text-align: left;">
                        For each iteration, we update $\delta'_t = x' - x$ based on our desired output $O^*=(b^*, c^*, p^*)$:
                    </p>
                    <p style="font-size: 24px;" class="fragment">
                        $$ \delta'_t = proj_p(\delta'_{t-1} + \alpha sign(\frac{\partial L^*(x'_{t-1};O^*)}{\partial x'_{t-1}} )) $$
                    </p>
                    <p style="font-size: 24px; text-align: left;" class="fragment">
                        How do we desgin the loss function?
                    </p>
                    <p style="font-size: 24px;" class="fragment">
                        Training Loss: $L^*(x', O^*) = L_{obj}^*(x', O^*) + L_{bbox}^*(x', O^*) + L_{class}^*(x', O^*)$
                    </p>
                    <div class="fragment">
                        <p style="font-size: 24px;">
                            Conjuring Loss: $L^*(x', O^*) = \sum{\sigma(c) * \sigma(p_i)}$
                        </p>
                        <p style="font-size: 24px;">
                            Vanishing Loss: $L^*(x', O^*) = -\sum{\sigma(c) * \sigma(p_i)}$
                        </p>
                    </div>
                    <div class="r-hstack">
                        <div class="r-vstack">
                            <img src="images/no_attack.gif">
                            <p class="" style="margin-top: 0; font-size: 20px;">No attack</p>
                        </div>
                        <div class="r-vstack">&nbsp;&nbsp;&nbsp;&nbsp;</div>
                        <div class="r-vstack">
                            <img src="images/attack.gif">
                            <p class="" style="margin-top: 0; font-size: 20px;">Under attack</p>
                        </div>
                    </div>
                    <aside class="notes">
                    </aside>
                </section> -->

                <section data-menu-title="Summary">
                    <p class="r-fit-text">Man-in-the-Middle Attack against Object Detection</p>
                    <img src="images/demo.jpg" />
                    <p class="name fragment" style="color: blue;font-size: 26px;">Is Deep Learning secure for Robots?</p>
                </section>

                <section>
                    <h2>Thanks</h2>
                    <div class="r-vstack">
                        <p><a href="https://minm.wuhanstudio.uk/">https://minm.wuhanstudio.uk</a></p>
                    </div>
                    <img src="images/qrcode.png" width="25%" />
                    <p style="font-size: 22px;"><i class="fab fa-github"></i> &nbsp; <a href="https://github.com/wuhanstudio/adversarial-camera">Source Code</a></p>
                </section>

            </div>
        </div>

        <script src="dist/reveal.js"></script>
        <script src="plugin/chalkboard/plugin.js"></script>
        <script src="plugin/customcontrols/plugin.js"></script>
        <script src="plugin/menu/menu.js"></script>
        <script src="plugin/math/math.js"></script>
        <script src="plugin/highlight/highlight.js"></script>

        <script>
            Reveal.initialize({
                center: true,
                hash: true,
                plugins: [ RevealHighlight, RevealMath, RevealMenu, RevealChalkboard, RevealCustomControls ],
                mathjax: 'https://cdn.jsdelivr.net/gh/mathjax/mathjax@2.7.8/MathJax.js',
                config: 'TeX-AMS_HTML-full',
                // pass other options into `MathJax.Hub.Config()`
                TeX: { Macros: { RR: "{\\bf R}" } },
                menu: {
                    hideMissingTitles: true,
                },
                chalkboard: {
                    boardmarkerWidth: 3,
                    chalkWidth: 7,
                    chalkEffect: 1.0,
                    storage: null,
                    src: null,
                    readOnly: undefined,
                    transition: 800,
                    theme: "chalkboard",
                    background: [ 'rgba(127,127,127,.1)' , path + 'img/blackboard.png' ],
                    grid: { color: 'rgb(50,50,10,0.5)', distance: 80, width: 2},
                    eraser: { src: path + 'img/sponge.png', radius: 20},
                    boardmarkers : [
                            { color: 'rgba(100,100,100,1)', cursor: 'url(' + path + 'img/boardmarker-black.png), auto'},
                            { color: 'rgba(30,144,255, 1)', cursor: 'url(' + path + 'img/boardmarker-blue.png), auto'},
                            { color: 'rgba(220,20,60,1)', cursor: 'url(' + path + 'img/boardmarker-red.png), auto'},
                            { color: 'rgba(50,205,50,1)', cursor: 'url(' + path + 'img/boardmarker-green.png), auto'},
                            { color: 'rgba(255,140,0,1)', cursor: 'url(' + path + 'img/boardmarker-orange.png), auto'},
                            { color: 'rgba(150,0,20150,1)', cursor: 'url(' + path + 'img/boardmarker-purple.png), auto'},
                            { color: 'rgba(255,220,0,1)', cursor: 'url(' + path + 'img/boardmarker-yellow.png), auto'}
                    ],
                    chalks: [
                            { color: 'rgba(255,255,255,0.5)', cursor: 'url(' + path + 'img/chalk-white.png), auto'},
                            { color: 'rgba(96, 154, 244, 0.5)', cursor: 'url(' + path + 'img/chalk-blue.png), auto'},
                            { color: 'rgba(237, 20, 28, 0.5)', cursor: 'url(' + path + 'img/chalk-red.png), auto'},
                            { color: 'rgba(20, 237, 28, 0.5)', cursor: 'url(' + path + 'img/chalk-green.png), auto'},
                            { color: 'rgba(220, 133, 41, 0.5)', cursor: 'url(' + path + 'img/chalk-orange.png), auto'},
                            { color: 'rgba(220,0,220,0.5)', cursor: 'url(' + path + 'img/chalk-purple.png), auto'},
                            { color: 'rgba(255,220,0,0.5)', cursor: 'url(' + path + 'img/chalk-yellow.png), auto'}
                    ]
                },
                customcontrols: {
                    controls: [
                        { icon: '<i class="fa fa-pen-square"></i>',
                        title: 'Toggle chalkboard (B)',
                        action: 'RevealChalkboard.toggleChalkboard();'
                        },
                        { icon: '<i class="fa fa-pen"></i>',
                        title: 'Toggle notes canvas (C)',
                        action: 'RevealChalkboard.toggleNotesCanvas();'
                        }
                    ]
                },
                // showNotes: true,
            });
        </script>
    </body>
</html>
